{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, LSTM, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Flatten, Reshape\n",
    "from keras.layers import Softmax, Input, Concatenate, Embedding, Activation, Lambda\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT, RIGHT_ONLY\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import gym\n",
    "from copy import copy\n",
    "\n",
    "\n",
    "\n",
    "#HYPER PARAMETERS\n",
    "BUFFER = 3\n",
    "PATIENCE = 5\n",
    "MAX_FRAMES = 3000\n",
    "STUCK_PENALTY = -50\n",
    "\n",
    "#SEMI HYPER PARAMETERS\n",
    "SKIP = 6\n",
    "LAYER_CHANCE = .33\n",
    "WEIGHT_CHANCE = .33\n",
    "MUT_FACTOR = .33\n",
    "SCORE_FACTOR = .2\n",
    "agent_id = 0\n",
    "\n",
    "\n",
    "MOVEMENT = COMPLEX_MOVEMENT\n",
    "GAME = 'SuperMarioBros-v3'\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.144]).astype('int')\n",
    "\n",
    "def prepare_frames(frames):\n",
    "    gray_frames = []\n",
    "    for frame in frames:\n",
    "        gray_frame = rgb2gray(frame)\n",
    "        gray_frames.append(gray_frame)\n",
    "    gray_frames = np.array(gray_frames)\n",
    "    return np.array([np.swapaxes(gray_frames, 0, 2)])\n",
    "        \n",
    "    \n",
    "class Model:\n",
    "    \n",
    "    def __init__(self, input_shape, output_dim, activation = 'relu'):\n",
    "        w, h, _ = input_shape\n",
    "        max_dim = max([w,h])    \n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_dim = output_dim\n",
    "        self.NN = Sequential()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.NN.add(Lambda(lambda x: x/255., input_shape = input_shape))        \n",
    "        self.NN.add(ZeroPadding2D(padding = ((max_dim - w)//2, (max_dim - h)//2)))\n",
    "        self.NN.add(MaxPooling2D((6,6)))\n",
    "        self.NN.add(Conv2D(4,\n",
    "                              4,\n",
    "                              strides=(2, 2),\n",
    "                              padding=\"same\",\n",
    "                              activation=activation))\n",
    "        self.NN.add(Conv2D(8,\n",
    "                              4,\n",
    "                              strides=(2, 2),\n",
    "                              padding=\"same\",\n",
    "                              activation=activation))\n",
    "        \n",
    "        self.NN.add(Conv2D(16,\n",
    "                              4,\n",
    "                              strides=(2, 2),\n",
    "                              padding=\"same\",\n",
    "                              activation=activation))\n",
    "        self.NN.add(Flatten())\n",
    "        self.NN.add(Dense(64, activation=activation))\n",
    "        self.NN.add(Dense(output_dim, activation = 'softmax'))\n",
    "        self.NN.compile(loss=\"mean_squared_error\",\n",
    "                           optimizer = 'rmsprop')\n",
    "    \n",
    "    \n",
    "    def summary(self):\n",
    "        return self.NN.summary()\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.NN.get_weights()\n",
    "        \n",
    "        \n",
    "class mario_agent:\n",
    "    \n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        global agent_id\n",
    "        self.id = agent_id\n",
    "        agent_id +=1\n",
    "        \n",
    "        self.score_factor = SCORE_FACTOR\n",
    "        \n",
    "        self.layer_chance = LAYER_CHANCE\n",
    "        self.weight_chance = WEIGHT_CHANCE\n",
    "        self.mut_factor = MUT_FACTOR\n",
    "        self.skip = SKIP\n",
    "        \n",
    "        self.max_frames = MAX_FRAMES\n",
    "        self.action_space = output_dim\n",
    "        self.buffer = BUFFER\n",
    "        self.patience = PATIENCE\n",
    "        self.fitness = None\n",
    "        self.w_fitness = 0\n",
    "        \n",
    "        self.last_action = []\n",
    "        self.optography = []\n",
    "        self.genealogy = deque(maxlen = self.buffer)\n",
    "        self.model = Model(input_shape, output_dim)\n",
    "        \n",
    "    def act(self, frames, prob = False):\n",
    "        q_values = self.model.NN.predict(frames)\n",
    "        if prob:\n",
    "            return q_values[0]\n",
    "        return np.argmax(q_values[0])\n",
    "    \n",
    "    def play(self, render = False, monitor = False):\n",
    "        env = gym_super_mario_bros.make(GAME)\n",
    "        env = JoypadSpace(env, MOVEMENT)\n",
    "        if monitor:\n",
    "            env = gym.wrappers.Monitor(env, \"./gym-results\", force=True)\n",
    "        env.reset()\n",
    "        \n",
    "        observation_space = env.observation_space.shape\n",
    "        action_space = env.action_space.n\n",
    "        action = 0\n",
    "        tot_reward = 0\n",
    "        agg_reward = 0\n",
    "        reward = 0\n",
    "        w_reward = 0\n",
    "         \n",
    "        stuck = 0\n",
    "        x_pos = 0\n",
    "        terminal = False\n",
    "        first = True\n",
    "        stuck_bool = False\n",
    "        \n",
    "        self.optography = deque(maxlen = self.buffer)\n",
    "        \n",
    "        for step in range(self.max_frames):\n",
    "            if render:\n",
    "                env.render()\n",
    "            if not terminal:\n",
    "                state, reward, terminal, info = env.step(action)\n",
    "            \n",
    "            if info['x_pos'] > x_pos:\n",
    "                x_pos = info['x_pos']\n",
    "                stuck = 0\n",
    "            else:\n",
    "                stuck+=1\n",
    "            \n",
    "            if stuck > self.patience*60:\n",
    "                reward = STUCK_PENALTY\n",
    "                stuck_bool = True\n",
    "            \n",
    "            tot_reward += reward\n",
    "            agg_reward += reward\n",
    "            \n",
    "            if info['stage'] != 1:\n",
    "                     # serialize model to JSON\n",
    "                model_json = model.to_json()\n",
    "                with open(\"model.json\", \"w\") as json_file:\n",
    "                    json_file.write(model_json)\n",
    "                    \n",
    "\n",
    "            if step % self.skip == 0:\n",
    "                self.optography.append(np.array(state))\n",
    "\n",
    "            if len(self.optography) == self.buffer:\n",
    "                \n",
    "                if info['life'] < 2:\n",
    "                    terminal = True\n",
    "                \n",
    "                frames = prepare_frames(self.optography)\n",
    "                q_values = self.act(frames, prob = True)\n",
    "                w_reward += np.max(q_values)*agg_reward\n",
    "                agg_reward = 0\n",
    "                action = np.argmax(q_values)\n",
    "            \n",
    "                if terminal or stuck_bool:\n",
    "                    env.close()\n",
    "                    self.fitness = tot_reward + info['score']*self.score_factor\n",
    "                    self.w_fitness = w_reward\n",
    "                    self.last_action = action\n",
    "                    return env\n",
    "\n",
    "\n",
    "        env.close()\n",
    "        self.fitness = tot_reward + info['score']*self.score_factor\n",
    "        self.w_fitness = w_reward\n",
    "        self.last_action = action\n",
    "        return env\n",
    "    \n",
    "    def get_fitness(self):\n",
    "        if self.fitness == None:\n",
    "            self.play()\n",
    "        return self.fitness\n",
    "    \n",
    "    def mutate_layer(self, layer):\n",
    "        weights = []\n",
    "        for weight in layer.get_weights():\n",
    "            new_weight = np.random.uniform(-0.05, 0.05, np.shape(weight))\n",
    "            for index in np.ndenumerate(weight):\n",
    "                if random.random() < self.weight_chance:\n",
    "                    weight[index[0]] += new_weight[index[0]]*self.mut_factor\n",
    "                    weight[index[0]] = min(0.05, weight[index[0]])\n",
    "                    weight[index[0]] = max(-0.05, weight[index[0]])\n",
    "            weights.append(weight)\n",
    "        layer.set_weights(weights)\n",
    "\n",
    "    def mutate(self):\n",
    "        self.fitness = None\n",
    "        for layer in self.model.NN.layers:\n",
    "            if random.random() < self.layer_chance:\n",
    "                self.mutate_layer(layer)\n",
    "                \n",
    "        \n",
    "        #self.layer_chance += random.randint(-1,1)*random.random()/10\n",
    "        #self.weight_chance += random.randint(-1,1)*random.random()/10\n",
    "        #self.mut_factor += random.randint(-1,1)*random.random()/10\n",
    "        self.skip = max(1,SKIP + random.randint(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fitness_hist = []\n",
    "\n",
    "env = gym_super_mario_bros.make(GAME)\n",
    "env = JoypadSpace(env, MOVEMENT)\n",
    "observation_space = env.observation_space.shape\n",
    "action_space = env.action_space.n\n",
    "agent = mario_agent((256, 240, BUFFER), action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 256, 240, 3)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 42, 42, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 21, 21, 4)         196       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 8)         520       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 16)          2064      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 40,488\n",
      "Trainable params: 40,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "agent.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "def update_ancestor(agent1, agent2):\n",
    "    if agent1.fitness != agent2.fitness:\n",
    "        genealogy = agent1.genealogy\n",
    "        genealogy.append((agent1.id, agent1.fitness))\n",
    "        agent2.genealogy = genealogy\n",
    "\n",
    "def transfer_weights(NN1, NN2):\n",
    "    for i in range(len(NN1.layers)):\n",
    "        NN2.layers[i].set_weights(copy(NN1.layers[i].get_weights()))\n",
    "        \n",
    "def same_last_action(agent):\n",
    "    frames = prepare_frames(agent.optography)\n",
    "    action = agent.act(frames)\n",
    "    return action == agent.last_action\n",
    "        \n",
    "def replicate(agent1, agent2, flashback = False, verbose = False):\n",
    "    update_ancestor(agent1, agent2)\n",
    "    transfer_weights(agent1.model.NN, agent2.model.NN)\n",
    "    \n",
    "    if flashback:\n",
    "        attempts = 0\n",
    "        while(same_last_action(agent2)):\n",
    "            agent2.mutate()\n",
    "            if verbose:\n",
    "                clear_output(wait = True)\n",
    "                attempts += 1\n",
    "                print(\"Mutation Attempts: \", attempts)\n",
    "    else:\n",
    "        agent2.mutate()\n",
    "\n",
    "    agent2.fitness = None\n",
    "    \n",
    "    global agent_id\n",
    "    agent2.id = agent_id\n",
    "    agent_id += 1\n",
    "    \n",
    "def get_next_gen(generation, flashback = False, verbose = False):\n",
    "    for l in range(LIV_SIZE):\n",
    "        for g in range(int(GEN_SIZE/LIV_SIZE) - 1):\n",
    "            #print(l, (l+1)*LIV_SIZE + g)\n",
    "            agent1 = generation[l]\n",
    "            agent2 = generation[(l+1)*LIV_SIZE + g]\n",
    "            replicate(agent1, agent2, flashback = flashback, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def generation_step(generation, flashback = False, verbose = False):\n",
    "    gen_fitness = [agent.get_fitness() for agent in generation]\n",
    "    w_fitness = [agent.w_fitness for agent in generation]\n",
    "    zipped = zip(generation, gen_fitness, w_fitness)\n",
    "    gen_sorted = list(reversed(sorted(zipped, key = operator.itemgetter(1, 2))))\n",
    "    generation, gen_fitness, w_fitness = list(zip(*gen_sorted))\n",
    "    get_next_gen(generation, flashback = flashback, verbose = verbose)\n",
    "    return generation, gen_fitness, w_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "LIV_SIZE = 4\n",
    "GEN_SIZE = (LIV_SIZE+1)*LIV_SIZE\n",
    "#GEN_SIZE = 5\n",
    "\n",
    "#creating generation 0\n",
    "generation = [mario_agent((256, 240, BUFFER), action_space) for _ in range(GEN_SIZE)]\n",
    "fitness_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ff9aae3cbdd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcurrent_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mgeneration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_fitness\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneration_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflashback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mfitness_hist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_fitness\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-957441d3b22e>\u001b[0m in \u001b[0;36mgeneration_step\u001b[1;34m(generation, flashback, verbose)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgeneration_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflashback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgen_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mw_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_fitness\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mzipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_fitness\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_fitness\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-957441d3b22e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgeneration_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflashback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgen_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mw_fitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_fitness\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mzipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_fitness\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_fitness\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-1de4c9bbb565>\u001b[0m in \u001b[0;36mget_fitness\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-1de4c9bbb565>\u001b[0m in \u001b[0;36mplay\u001b[1;34m(self, render, monitor)\u001b[0m\n\u001b[0;32m    186\u001b[0m                     \u001b[0mterminal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                 \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptography\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m                 \u001b[0mq_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                 \u001b[0mw_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0magg_reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-1de4c9bbb565>\u001b[0m in \u001b[0;36mprepare_frames\u001b[1;34m(frames)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mgray_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mgray_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrgb2gray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mgray_frames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mgray_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-1de4c9bbb565>\u001b[0m in \u001b[0;36mrgb2gray\u001b[1;34m(rgb)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrgb2gray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.299\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.587\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.144\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprepare_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    current_time = time.time()\n",
    "    generation, gen_fitness, w_fitness = generation_step(generation, flashback = False, verbose = False)\n",
    "    fitness_hist.append(max(gen_fitness))\n",
    "    clear_output(wait = True)\n",
    "    #print('gen_fitness: ', gen_fitness)\n",
    "    #print('w_fitness: ', w_fitness)\n",
    "\n",
    "    plt.title('Survival of the fittest')\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.plot(fitness_hist)\n",
    "    plt.show()\n",
    "\n",
    "    print('Generation Time: ', time.time() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "env = generation[0].play(monitor = True)\n",
    "\n",
    "video = io.open('./gym-results/openaigym.video.%s.video000000.mp4' % env.file_infix, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''\n",
    "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
    ".format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
